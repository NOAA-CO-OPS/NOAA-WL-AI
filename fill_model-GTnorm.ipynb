{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to start exporing gap filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dill\n",
    "from scipy import io\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, GRU\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#My helper functions\n",
    "from modelNN_functions import assessTrainTestData\n",
    "from modelNN_functions import plotConfusionMatrix\n",
    "from modelNN_functions import pandasToMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('notebook_fillModel.db')\n",
    "#dill.load_session('notebook_fillModel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets, \n",
    "               epochCount, batchCount, numFeatures):\n",
    "\n",
    "    \"\"\"\n",
    "    where: \n",
    "        featureTrain = features used in training the model\n",
    "        targetTrain = targets (verified water level obs) used in training the model\n",
    "        featureTest = features used for validation\n",
    "        targetTest = targets (verified water level obs) used for valdation\n",
    "        predictFeatures = the features for the model predictions\n",
    "        predictTargets = the targets for the model predictions\n",
    "        epochCount = number of training cycles to use for NN model (10-20 seems reasonable)\n",
    "        batchCount = the batch size to use when training (somewhere from 32-256 seems reasonable)\n",
    "        numFeatures = the number of input features in the NN model\n",
    "    \"\"\"\n",
    "\n",
    "    #First define the keras NN framework to be used\n",
    "    # For a regression model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=numFeatures))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', input_dim=numFeatures))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', input_dim=numFeatures))\n",
    "    model.add(Dense(1))\n",
    "    #Changing the learning rate from 0.001 (default) to speed up convergence\n",
    "    adamOpt = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=adamOpt,\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    #Set up the model checkpoint\n",
    "    # checkpoint\n",
    "    filepath=\"fillmodel_best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # Train the model, iterating on the data in batches of X # samples (somewhere between 32 - 256)\n",
    "    history = model.fit(featureTrain, targetTrain, epochs=epochCount, batch_size=batchCount, validation_data=(featureTest, targetTest),callbacks=callbacks_list)\n",
    "    \n",
    "    #Evaulate the model\n",
    "    eval_model=model.evaluate(featureTest, targetTest)\n",
    "    eval_model\n",
    "    \n",
    "    #Plot the NN loss over each epoch\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history['loss'])\n",
    "    ax.plot(history.history['val_loss'])\n",
    "    ax.legend(['Training','Validation'])\n",
    "    plt.show()\n",
    "    #fig.savefig('NN_modelTrainingHistory.png')\n",
    "\n",
    "    #Generate model predictions for the validation period\n",
    "    #modelPrediction = model.predict(predictFeatures, batch_size=32)\n",
    "    \n",
    "    modelOut = pd.DataFrame()\n",
    "    #modelOut['verified'] = predictTargets['verified']\n",
    "    #modelOut['modelPrediction']=modelPrediction[:,0]    \n",
    "    \n",
    "    return modelOut, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = pd.read_pickle(Path(\"pickle_files/8536110_cm_raw_ver_merged_wl_Cleaned\"))\n",
    "neighbor = pd.read_pickle(Path(\"pickle_files/8557380_lewes_raw_ver_merged_wl_Cleaned\"))\n",
    "\n",
    "#cleaned = pd.read_pickle(Path(\"pickle_files/8557380_lewes_raw_ver_merged_wl_Cleaned\"))\n",
    "#neighbor = pd.read_pickle(Path(\"pickle_files/8536110_cm_raw_ver_merged_wl_Cleaned\"))\n",
    "\n",
    "#cleaned = pd.read_pickle(Path(\"pickle_files/8534720_ac_raw_ver_merged_wl_Cleaned\"))\n",
    "#neighbor = pd.read_pickle(Path(\"pickle_files/8536110_cm_raw_ver_merged_wl_Cleaned\"))\n",
    "\n",
    "#cleaned = pd.read_pickle(Path(\"pickle_files/8443970_boston_raw_ver_merged_wl_Cleaned\"))\n",
    "#neighbor = pd.read_pickle(Path(\"pickle_files/8418150_portland_raw_ver_merged_wl_Cleaned\"))\n",
    "\n",
    "#cleaned = pd.read_pickle(Path(\"pickle_files/8418150_portland_raw_ver_merged_wl_Cleaned\"))\n",
    "#neighbor = pd.read_pickle(Path(\"pickle_files/8443970_boston_raw_ver_merged_wl_Cleaned\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPT if you run this cell twice it will mess up since I am replacing all the NaNs (e.g. the next time through will have none)\n",
    "\n",
    "primaryTrue = cleaned['primary'].notnull()\n",
    "cleaned['primaryTrue'] = primaryTrue * 1\n",
    "\n",
    "sigmaTrue = cleaned['sigma'].notnull()\n",
    "cleaned['sigmaTrue'] = sigmaTrue * 1\n",
    "\n",
    "backupTrue = cleaned['backup'].notnull()\n",
    "cleaned['backupTrue'] = backupTrue * 1\n",
    "\n",
    "cleaned['primary'].fillna(value=0, inplace = True)\n",
    "cleaned['sigma'].fillna(value=0, inplace = True)\n",
    "cleaned['backup'].fillna(value=0, inplace = True)\n",
    "cleaned['residual'].fillna(value=0, inplace = True)\n",
    "cleaned['targets'].fillna(value=0, inplace = True)\n",
    "\n",
    "#If the primary or residual was deamed bad, we should also be setting the value to 0, since it would be dropped\n",
    "cleaned['primary']=cleaned['primary']*cleaned['targets']\n",
    "cleaned['primaryTrue']=cleaned['primaryTrue']*cleaned['targets']\n",
    "cleaned['residual']=cleaned['residual']*cleaned['targets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE SAME PROCESS BUT FOR THE NEIGHBOR STATION RESIDUAL\n",
    "\n",
    "neighborResidualTrue = neighbor['residual'].notnull()\n",
    "neighbor['residualTrue'] = neighborResidualTrue * 1\n",
    "\n",
    "neighbor['residual'].fillna(value=0, inplace = True)\n",
    "neighbor['targets'].fillna(value=0, inplace = True)\n",
    "\n",
    "neighbor['residual']=neighbor['residual']*neighbor['targets']\n",
    "neighbor['residualTrue']=neighbor['residualTrue']*neighbor['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now add neighbor residual to the main cleaned dataframe\n",
    "cleaned['neighborResidual']=neighbor['residual']\n",
    "cleaned['neighborResidualTrue']=neighbor['residualTrue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['backupTrue'] = cleaned['backupTrue'].mask(cleaned['backup'].abs() >4, 0)\n",
    "cleaned['backup'] = cleaned['backup'].mask(cleaned['backup'].abs() >4, 0)\n",
    "cleaned['backupResidual'] = (cleaned['backup']-cleaned['prediction']) * cleaned['backupTrue']\n",
    "\n",
    "cleaned['sigma'] = cleaned['sigma'].mask(cleaned['sigma'].abs() > 1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>sigma</th>\n",
       "      <th>backup</th>\n",
       "      <th>verified</th>\n",
       "      <th>prediction</th>\n",
       "      <th>residual</th>\n",
       "      <th>targets</th>\n",
       "      <th>primaryTrue</th>\n",
       "      <th>sigmaTrue</th>\n",
       "      <th>backupTrue</th>\n",
       "      <th>neighborResidual</th>\n",
       "      <th>neighborResidualTrue</th>\n",
       "      <th>backupResidual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:00:00</th>\n",
       "      <td>0.276673</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.268837</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.232068</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:06:00</th>\n",
       "      <td>0.263412</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.256178</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.220012</td>\n",
       "      <td>0.072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:12:00</th>\n",
       "      <td>0.241109</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.233876</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.207354</td>\n",
       "      <td>0.056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:18:00</th>\n",
       "      <td>0.226643</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.218807</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.193490</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:24:00</th>\n",
       "      <td>0.213382</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.206148</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      primary  sigma    backup  verified  prediction  \\\n",
       "time                                                                   \n",
       "2007-01-01 00:00:00  0.276673  0.006  0.268837     0.459    0.232068   \n",
       "2007-01-01 00:06:00  0.263412  0.005  0.256178     0.437    0.220012   \n",
       "2007-01-01 00:12:00  0.241109  0.006  0.233876     0.400    0.207354   \n",
       "2007-01-01 00:18:00  0.226643  0.006  0.218807     0.376    0.193490   \n",
       "2007-01-01 00:24:00  0.213382  0.006  0.206148     0.354    0.179024   \n",
       "\n",
       "                     residual  targets  primaryTrue  sigmaTrue  backupTrue  \\\n",
       "time                                                                         \n",
       "2007-01-01 00:00:00     0.074      1.0          1.0          1           1   \n",
       "2007-01-01 00:06:00     0.072      1.0          1.0          1           1   \n",
       "2007-01-01 00:12:00     0.056      1.0          1.0          1           1   \n",
       "2007-01-01 00:18:00     0.055      1.0          1.0          1           1   \n",
       "2007-01-01 00:24:00     0.057      1.0          1.0          1           1   \n",
       "\n",
       "                     neighborResidual  neighborResidualTrue  backupResidual  \n",
       "time                                                                         \n",
       "2007-01-01 00:00:00             0.068                   1.0           0.061  \n",
       "2007-01-01 00:06:00             0.064                   1.0           0.060  \n",
       "2007-01-01 00:12:00             0.055                   1.0           0.044  \n",
       "2007-01-01 00:18:00             0.059                   1.0           0.042  \n",
       "2007-01-01 00:24:00             0.042                   1.0           0.045  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling - trying scaling by the Great Diurnal range, and NOT scaling residual.  The residual is fairly normally distributed about 0 and the observed and predicted values run pretty consistently \n",
    "#between -1 and 1 when scaled by the GDT range.\n",
    "\n",
    "CapeMayRange=1.659\n",
    "GDTrange = CapeMayRange\n",
    "\n",
    "#What columns are being Scaled\n",
    "names = ['primary','backup','prediction']\n",
    "# Fit your data on the scaler object\n",
    "cleanedScaled=cleaned.copy()\n",
    "cleanedScaled.loc[:,names] = cleanedScaled.loc[:,names] / GDTrange\n",
    "\n",
    "cleanedScaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CPU times: user 20.4 ms, sys: 98 µs, total: 20.5 ms\n",
      "Wall time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Add a feature for primary, which effectively estimates the gap width.  So how many points forward and backward\n",
    "#in time until I have a good value (up to some maximum distance - thinking of using 12 hours\n",
    "\n",
    "#primaryTF = cleaned['primaryTrue'].where(cleaned['primaryTrue'] == 1)\n",
    "primaryTF = cleaned['primaryTrue']\n",
    "primaryTF = primaryTF.reset_index()\n",
    "primaryTF.drop(['time'], axis=1,inplace = True)\n",
    "prevGap = primaryTF.copy()*0\n",
    "\n",
    "for row in primaryTF.iloc[1:10].itertuples():\n",
    "    ind = row[0]\n",
    "    #if (primaryTF.iloc[ind-1] == 1) and (primaryTF.iloc[ind+1] == 1):\n",
    "    if primaryTF.primaryTrue.iloc[ind] == 1:\n",
    "        print(primaryTF.primaryTrue.iloc[ind])\n",
    "\n",
    "    \n",
    "    \n",
    "   # startIndex=indexStop-120\n",
    "    #if startIndex < 0:\n",
    "     #   startIndex = 0\n",
    "    #values = primaryTF.iloc[startIndex:indexStop]\n",
    "    #prevGap.iloc[indexStop] = values.last_valid_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primaryTrue    1.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primaryTF.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>sigma</th>\n",
       "      <th>backup</th>\n",
       "      <th>verified</th>\n",
       "      <th>prediction</th>\n",
       "      <th>residual</th>\n",
       "      <th>targets</th>\n",
       "      <th>primaryTrue</th>\n",
       "      <th>sigmaTrue</th>\n",
       "      <th>backupTrue</th>\n",
       "      <th>...</th>\n",
       "      <th>residualPrev18</th>\n",
       "      <th>primaryNext6</th>\n",
       "      <th>primaryTrueNext6</th>\n",
       "      <th>residualNext6</th>\n",
       "      <th>primaryNext12</th>\n",
       "      <th>primaryTrueNext12</th>\n",
       "      <th>residualNext12</th>\n",
       "      <th>primaryNext18</th>\n",
       "      <th>primaryTrueNext18</th>\n",
       "      <th>residualNext18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:18:00</th>\n",
       "      <td>0.226643</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.218807</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.193490</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.213382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.201929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.184448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:24:00</th>\n",
       "      <td>0.213382</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.206148</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.201929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.184448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.171187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:30:00</th>\n",
       "      <td>0.201929</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.195298</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.163954</td>\n",
       "      <td>0.063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.184448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.171187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:36:00</th>\n",
       "      <td>0.184448</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.177818</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.147679</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.171187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.132610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:42:00</th>\n",
       "      <td>0.171187</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.165160</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.155515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.132610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.111513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:12:00</th>\n",
       "      <td>0.338758</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.359855</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.376733</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.344786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:18:00</th>\n",
       "      <td>0.344786</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.366486</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.387583</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.367691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:24:00</th>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.374925</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.396624</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.367691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:30:00</th>\n",
       "      <td>0.368294</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.391802</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.403858</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.367691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:36:00</th>\n",
       "      <td>0.367691</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.410488</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.368294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.373719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961219 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      primary  sigma    backup  verified  prediction  \\\n",
       "time                                                                   \n",
       "2007-01-01 00:18:00  0.226643  0.006  0.218807     0.376    0.193490   \n",
       "2007-01-01 00:24:00  0.213382  0.006  0.206148     0.354    0.179024   \n",
       "2007-01-01 00:30:00  0.201929  0.004  0.195298     0.335    0.163954   \n",
       "2007-01-01 00:36:00  0.184448  0.008  0.177818     0.306    0.147679   \n",
       "2007-01-01 00:42:00  0.171187  0.004  0.165160     0.284    0.130802   \n",
       "...                       ...    ...       ...       ...         ...   \n",
       "2017-12-31 23:12:00  0.338758  0.020  0.359855     0.562    0.376733   \n",
       "2017-12-31 23:18:00  0.344786  0.023  0.366486     0.572    0.387583   \n",
       "2017-12-31 23:24:00  0.352019  0.022  0.374925     0.584    0.396624   \n",
       "2017-12-31 23:30:00  0.368294  0.014  0.391802     0.611    0.403858   \n",
       "2017-12-31 23:36:00  0.367691  0.017  0.391200     0.610    0.410488   \n",
       "\n",
       "                     residual  targets  primaryTrue  sigmaTrue  backupTrue  \\\n",
       "time                                                                         \n",
       "2007-01-01 00:18:00     0.055      1.0          1.0          1           1   \n",
       "2007-01-01 00:24:00     0.057      1.0          1.0          1           1   \n",
       "2007-01-01 00:30:00     0.063      1.0          1.0          1           1   \n",
       "2007-01-01 00:36:00     0.061      1.0          1.0          1           1   \n",
       "2007-01-01 00:42:00     0.067      1.0          1.0          1           1   \n",
       "...                       ...      ...          ...        ...         ...   \n",
       "2017-12-31 23:12:00    -0.063      1.0          1.0          1           1   \n",
       "2017-12-31 23:18:00    -0.071      1.0          1.0          1           1   \n",
       "2017-12-31 23:24:00    -0.074      1.0          1.0          1           1   \n",
       "2017-12-31 23:30:00    -0.059      1.0          1.0          1           1   \n",
       "2017-12-31 23:36:00    -0.071      1.0          1.0          1           1   \n",
       "\n",
       "                     ...  residualPrev18  primaryNext6  primaryTrueNext6  \\\n",
       "time                 ...                                                   \n",
       "2007-01-01 00:18:00  ...           0.074      0.213382               1.0   \n",
       "2007-01-01 00:24:00  ...           0.072      0.201929               1.0   \n",
       "2007-01-01 00:30:00  ...           0.056      0.184448               1.0   \n",
       "2007-01-01 00:36:00  ...           0.055      0.171187               1.0   \n",
       "2007-01-01 00:42:00  ...           0.057      0.155515               1.0   \n",
       "...                  ...             ...           ...               ...   \n",
       "2017-12-31 23:12:00  ...          -0.054      0.344786               1.0   \n",
       "2017-12-31 23:18:00  ...          -0.052      0.352019               1.0   \n",
       "2017-12-31 23:24:00  ...          -0.063      0.368294               1.0   \n",
       "2017-12-31 23:30:00  ...          -0.063      0.367691               1.0   \n",
       "2017-12-31 23:36:00  ...          -0.071      0.368294               1.0   \n",
       "\n",
       "                     residualNext6  primaryNext12  primaryTrueNext12  \\\n",
       "time                                                                   \n",
       "2007-01-01 00:18:00          0.057       0.201929                1.0   \n",
       "2007-01-01 00:24:00          0.063       0.184448                1.0   \n",
       "2007-01-01 00:30:00          0.061       0.171187                1.0   \n",
       "2007-01-01 00:36:00          0.067       0.155515                1.0   \n",
       "2007-01-01 00:42:00          0.070       0.132610                1.0   \n",
       "...                            ...            ...                ...   \n",
       "2017-12-31 23:12:00         -0.071       0.352019                1.0   \n",
       "2017-12-31 23:18:00         -0.074       0.368294                1.0   \n",
       "2017-12-31 23:24:00         -0.059       0.367691                1.0   \n",
       "2017-12-31 23:30:00         -0.071       0.368294                1.0   \n",
       "2017-12-31 23:36:00         -0.077       0.369500                1.0   \n",
       "\n",
       "                     residualNext12  primaryNext18  primaryTrueNext18  \\\n",
       "time                                                                    \n",
       "2007-01-01 00:18:00           0.063       0.184448                1.0   \n",
       "2007-01-01 00:24:00           0.061       0.171187                1.0   \n",
       "2007-01-01 00:30:00           0.067       0.155515                1.0   \n",
       "2007-01-01 00:36:00           0.070       0.132610                1.0   \n",
       "2007-01-01 00:42:00           0.062       0.111513                1.0   \n",
       "...                             ...            ...                ...   \n",
       "2017-12-31 23:12:00          -0.074       0.368294                1.0   \n",
       "2017-12-31 23:18:00          -0.059       0.367691                1.0   \n",
       "2017-12-31 23:24:00          -0.071       0.368294                1.0   \n",
       "2017-12-31 23:30:00          -0.077       0.369500                1.0   \n",
       "2017-12-31 23:36:00          -0.081       0.373719                1.0   \n",
       "\n",
       "                     residualNext18  \n",
       "time                                 \n",
       "2007-01-01 00:18:00           0.061  \n",
       "2007-01-01 00:24:00           0.067  \n",
       "2007-01-01 00:30:00           0.070  \n",
       "2007-01-01 00:36:00           0.062  \n",
       "2007-01-01 00:42:00           0.058  \n",
       "...                             ...  \n",
       "2017-12-31 23:12:00          -0.059  \n",
       "2017-12-31 23:18:00          -0.071  \n",
       "2017-12-31 23:24:00          -0.077  \n",
       "2017-12-31 23:30:00          -0.081  \n",
       "2017-12-31 23:36:00          -0.076  \n",
       "\n",
       "[961219 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now create a previous 6 and 12 minute value and following 6 and 12 minute value of the primary (and boolean) and the residual (and boolean)\n",
    "#Prev 6 min\n",
    "cleanedScaled['primaryPrev6']=cleanedScaled['primary'].shift(periods = 1)\n",
    "cleanedScaled['primaryTruePrev6']=cleanedScaled['primaryTrue'].shift(periods = 1)\n",
    "cleanedScaled['residualPrev6']=cleanedScaled['residual'].shift(periods = 1)\n",
    "#Prev 12 min\n",
    "cleanedScaled['primaryPrev12']=cleanedScaled['primary'].shift(periods = 2)\n",
    "cleanedScaled['primaryTruePrev12']=cleanedScaled['primaryTrue'].shift(periods = 2)\n",
    "cleanedScaled['residualPrev12']=cleanedScaled['residual'].shift(periods = 2)\n",
    "#Prev 18 min\n",
    "cleanedScaled['primaryPrev18']=cleanedScaled['primary'].shift(periods = 3)\n",
    "cleanedScaled['primaryTruePrev18']=cleanedScaled['primaryTrue'].shift(periods = 3)\n",
    "cleanedScaled['residualPrev18']=cleanedScaled['residual'].shift(periods = 3)\n",
    "\n",
    "#Next 6 min\n",
    "cleanedScaled['primaryNext6']=cleanedScaled['primary'].shift(periods = -1)\n",
    "cleanedScaled['primaryTrueNext6']=cleanedScaled['primaryTrue'].shift(periods = -1)\n",
    "cleanedScaled['residualNext6']=cleanedScaled['residual'].shift(periods = -1)\n",
    "#Next 12 min\n",
    "cleanedScaled['primaryNext12']=cleanedScaled['primary'].shift(periods = -2)\n",
    "cleanedScaled['primaryTrueNext12']=cleanedScaled['primaryTrue'].shift(periods = -2)\n",
    "cleanedScaled['residualNext12']=cleanedScaled['residual'].shift(periods = -2)\n",
    "#Next 18 min\n",
    "cleanedScaled['primaryNext18']=cleanedScaled['primary'].shift(periods = -3)\n",
    "cleanedScaled['primaryTrueNext18']=cleanedScaled['primaryTrue'].shift(periods = -3)\n",
    "cleanedScaled['residualNext18']=cleanedScaled['residual'].shift(periods = -3)\n",
    "\n",
    "\n",
    "#And drop the first and last 18 minutes (3points)\n",
    "cleanedScaled.drop(cleanedScaled.head(3).index, inplace=True)\n",
    "cleanedScaled.drop(cleanedScaled.tail(3).index, inplace=True)\n",
    "\n",
    "#Just to be sure - drop any nan values (though I think all of these should have already been set to 0)\n",
    "cleanedScaled = cleanedScaled.dropna()\n",
    "\n",
    "cleanedScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScaled = cleanedScaled.loc[:'2014-12-31 23:54:00']\n",
    "testScaled = cleanedScaled.loc['2015-01-01 00:00:00':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the test data (and potentially for training data) we are going to remove the cases where the primary was used, \n",
    "#since we are trying to only assess times when humans filled the data.\n",
    "testScaled = testScaled[testScaled.targets == 0]\n",
    "#trainScaled = trainScaled[trainScaled.targets == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is to cat the initial 5 training sets together.  Right now just using 1 however.\n",
    "\n",
    "#capeMayTrain=trainScaled.copy()\n",
    "#capeMayTest=testScaled.copy()\n",
    "#capeMayTrain['stationName']='Cape May'\n",
    "#capeMayTest['stationName']='Cape May'\n",
    "\n",
    "#lewesTrain=trainScaled.copy()\n",
    "#lewesTest=testScaled.copy()\n",
    "#lewesTrain['stationName']='Lewes'\n",
    "#lewesTest['stationName']='Lewes'\n",
    "\n",
    "#acTrain=trainScaled.copy()\n",
    "#acTest=testScaled.copy()\n",
    "#acTrain['stationName']='Atlantic City'\n",
    "#acTest['stationName']='Atlantic City'\n",
    "\n",
    "#bostonTrain=trainScaled.copy()\n",
    "#bostonTest=testScaled.copy()\n",
    "#bostonTrain['stationName']='Boston'\n",
    "#bostonTest['stationName']='Boston'\n",
    "\n",
    "#portlandTrain=trainScaled.copy()\n",
    "#portlandTest=testScaled.copy()\n",
    "#portlandTrain['stationName']='Portland'\n",
    "#portlandTest['stationName']='Portland'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this cell if combining multiple stations together in one dataframe\n",
    "\n",
    "#del trainScaled\n",
    "#del testScaled\n",
    "#trainScaled = pd.concat([capeMayTrain, lewesTrain, acTrain, bostonTrain, portlandTrain])\n",
    "#testScaled = pd.concat([capeMayTest, lewesTest, acTest, bostonTest, portlandTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Points = 698182\n",
      "Total Testing Points = 5175\n"
     ]
    }
   ],
   "source": [
    "print('Total Training Points = ' + str(trainScaled.shape[0]))\n",
    "print('Total Testing Points = ' + str(testScaled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRand=shuffle(trainScaled)\n",
    "testRand=shuffle(testScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Feature Set\n",
    "featureNames = ['primaryPrev6','primaryPrev12','primaryPrev18','primaryNext6','primaryNext12','primaryNext18','backup','prediction','residualPrev6',\n",
    "                              'residualPrev12','residualPrev18','residualNext6','residualNext12','residualNext18','primaryTruePrev6','primaryTruePrev12','primaryTruePrev18','primaryTrueNext6',\n",
    "                              'primaryTrueNext12','primaryTrueNext18','backupTrue','neighborResidual','neighborResidualTrue','backupResidual']\n",
    "\n",
    "featureTrain = trainRand.loc[:,featureNames]\n",
    "featureTest = testRand.loc[:,featureNames]\n",
    "targetTrain=trainRand.loc[:,['verified']]\n",
    "targetTest=testRand.loc[:,['verified']]\n",
    "\n",
    "predictFeatures = testScaled.loc[:,featureNames]\n",
    "predictTargets = testScaled.loc[:,'verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the baseiline error (in this case the error in using the tide predictions alone)\n",
    "mae_tidePredictions = mean_absolute_error(test['prediction'],test['verified'])\n",
    "print('mae baseline = '+ str(mae_tidePredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 698182 samples, validate on 5175 samples\n",
      "Epoch 1/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 6.5418e-04 - mae: 0.0115 - val_loss: 0.0059 - val_mae: 0.0489\n",
      "Epoch 2/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.9219e-04 - mae: 0.0092 - val_loss: 0.0043 - val_mae: 0.0450\n",
      "Epoch 3/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.8004e-04 - mae: 0.0089 - val_loss: 0.0029 - val_mae: 0.0308\n",
      "Epoch 4/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.6924e-04 - mae: 0.0087 - val_loss: 0.0026 - val_mae: 0.0288\n",
      "Epoch 5/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.6268e-04 - mae: 0.0084 - val_loss: 0.0024 - val_mae: 0.0282\n",
      "Epoch 6/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.5874e-04 - mae: 0.0083 - val_loss: 0.0032 - val_mae: 0.0329\n",
      "Epoch 7/20\n",
      "698182/698182 [==============================] - 13s 18us/step - loss: 1.5433e-04 - mae: 0.0082 - val_loss: 0.0029 - val_mae: 0.0292\n",
      "Epoch 8/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.5242e-04 - mae: 0.0082 - val_loss: 0.0027 - val_mae: 0.0332\n",
      "Epoch 9/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.4832e-04 - mae: 0.0080 - val_loss: 0.0019 - val_mae: 0.0262\n",
      "Epoch 10/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.4764e-04 - mae: 0.0080 - val_loss: 0.0024 - val_mae: 0.0363\n",
      "Epoch 11/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.4493e-04 - mae: 0.0080 - val_loss: 0.0025 - val_mae: 0.0320\n",
      "Epoch 12/20\n",
      "698182/698182 [==============================] - 12s 18us/step - loss: 1.4444e-04 - mae: 0.0079 - val_loss: 0.0023 - val_mae: 0.0282\n",
      "Epoch 13/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.4450e-04 - mae: 0.0079 - val_loss: 0.0019 - val_mae: 0.0274\n",
      "Epoch 14/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.4186e-04 - mae: 0.0079 - val_loss: 0.0028 - val_mae: 0.0277\n",
      "Epoch 15/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.4100e-04 - mae: 0.0078 - val_loss: 0.0026 - val_mae: 0.0288\n",
      "Epoch 16/20\n",
      "698182/698182 [==============================] - 12s 17us/step - loss: 1.4127e-04 - mae: 0.0079 - val_loss: 0.0022 - val_mae: 0.0277\n",
      "Epoch 17/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.4022e-04 - mae: 0.0078 - val_loss: 0.0027 - val_mae: 0.0308\n",
      "Epoch 18/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.3844e-04 - mae: 0.0078 - val_loss: 0.0020 - val_mae: 0.0282\n",
      "Epoch 19/20\n",
      "698182/698182 [==============================] - 11s 16us/step - loss: 1.3919e-04 - mae: 0.0078 - val_loss: 0.0026 - val_mae: 0.0301\n",
      "Epoch 20/20\n",
      "698182/698182 [==============================] - 12s 18us/step - loss: 1.3757e-04 - mae: 0.0077 - val_loss: 0.0019 - val_mae: 0.0266\n",
      "5175/5175 [==============================] - 0s 54us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Going back to trying a standard dense NN with just CM\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = len(featureNames)\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best simple 5 station model\n",
    "model = load_model('fillmodel_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions from the best model\n",
    "modelPrediction = model.predict(predictFeatures, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate example predictions for Cape May\n",
    "#Now for the simple model\n",
    "modelOut=testScaled.copy()\n",
    "modelOut['modelPrediction']=modelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVerified= cleanedScaled.loc['2015-01-01 00:00:00':,'verified'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5175 entries, 2015-01-11 06:12:00 to 2017-12-14 15:36:00\n",
      "Data columns (total 24 columns):\n",
      "primaryPrev6            5175 non-null float64\n",
      "primaryPrev12           5175 non-null float64\n",
      "primaryPrev18           5175 non-null float64\n",
      "primaryNext6            5175 non-null float64\n",
      "primaryNext12           5175 non-null float64\n",
      "primaryNext18           5175 non-null float64\n",
      "backup                  5175 non-null float64\n",
      "prediction              5175 non-null float64\n",
      "residualPrev6           5175 non-null float64\n",
      "residualPrev12          5175 non-null float64\n",
      "residualPrev18          5175 non-null float64\n",
      "residualNext6           5175 non-null float64\n",
      "residualNext12          5175 non-null float64\n",
      "residualNext18          5175 non-null float64\n",
      "primaryTruePrev6        5175 non-null float64\n",
      "primaryTruePrev12       5175 non-null float64\n",
      "primaryTruePrev18       5175 non-null float64\n",
      "primaryTrueNext6        5175 non-null float64\n",
      "primaryTrueNext12       5175 non-null float64\n",
      "primaryTrueNext18       5175 non-null float64\n",
      "backupTrue              5175 non-null int64\n",
      "neighborResidual        5175 non-null float64\n",
      "neighborResidualTrue    5175 non-null float64\n",
      "backupResidual          5175 non-null float64\n",
      "dtypes: float64(23), int64(1)\n",
      "memory usage: 1010.7 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasToMat(modelOut, predictFeatures, 'CapeMayFill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to output just the entire test verified time series\n",
    "io.savemat(file_name = 'capeMayVerified.mat', mdict = testVerified.to_dict('list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4fb0710f07de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandasToMat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestVerified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestVerified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CapeMayFill_verified'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NOAA-WL-AI/modelNN_functions.py\u001b[0m in \u001b[0;36mpandasToMat\u001b[0;34m(modelOut, predictFeatures, outfileName)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_time.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_modelOut.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_predictFeatures.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wlai/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, into)\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \"\"\"\n\u001b[1;32m   1782\u001b[0m         \u001b[0;31m# GH16122\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m         \u001b[0minto_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minto_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wlai/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mstandardize_mapping\u001b[0;34m(into)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0minto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unsupported type: {into}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minto\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to_dict() only accepts initialized defaultdicts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "pandasToMat(testVerified, testVerified, 'CapeMayFill_verified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial test with CM data - filling gaps (Using all times to train) - with Standard Scaler\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = 23\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelOut['verified'],modelOut['modelPrediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasToMat(modelOut, predictFeatures, 'Fill_CapeMay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing now with Lewes data - filling gaps (Using all times to train) - with Standard Scaler\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = 23\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(modelOut['verified'],modelOut['modelPrediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasToMat(modelOut, predictFeatures, 'Fill_Lewes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing now with AC data - filling gaps (Using all times to train) - with Standard Scaler\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = 23\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing now with Boston data - filling gaps (Using all times to train) - with Standard Scaler\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = 23\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial test with all data - filling gaps (Using all times to train) - with Standard Scaler\n",
    "\n",
    "epochCount = 20\n",
    "batchCount = 256\n",
    "numFeatures = 23\n",
    "modelOut, model = runNNmodel(featureTrain, targetTrain, featureTest, targetTest, predictFeatures, predictTargets,\n",
    "               epochCount, batchCount, numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to prep targets for fitting in scikit-learn\n",
    "targetTrainIn=np.ravel(targetTrain)\n",
    "targetTestIn=np.ravel(targetTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 525 ms, total: 1.53 s\n",
      "Wall time: 541 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting a linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "clf.fit(featureTrain, targetTrainIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae train = 0.016983520452282064\n",
      "mae test = 0.1338843485820959\n",
      "mse test = 0.026510597733782424\n"
     ]
    }
   ],
   "source": [
    "# prediction on the training dataset\n",
    "mae_train = mean_absolute_error(clf.predict(featureTrain),targetTrain['verified'])\n",
    "print('mae train = '+ str(mae_train))\n",
    "\n",
    "# prediction on the testing dataset\n",
    "mae_test = mean_absolute_error(clf.predict(featureTest),targetTest['verified'])\n",
    "print('mae test = '+ str(mae_test))\n",
    "\n",
    "# prediction on the testing dataset\n",
    "mse_test = mean_squared_error(clf.predict(featureTest),targetTest['verified'])\n",
    "print('mse test = '+ str(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47min 39s, sys: 8.66 s, total: 47min 47s\n",
      "Wall time: 6min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=2, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "                      oob_score=False, random_state=None, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fitting a Random Forest\n",
    "clf = RandomForestRegressor(n_estimators=200, n_jobs=-1, max_depth=20, min_samples_leaf=2)\n",
    "clf.fit(featureTrain, targetTrainIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae train = 0.004349736374769333\n",
      "mae test = 0.029566667674836435\n",
      "mse test = 0.0035992274597379612\n"
     ]
    }
   ],
   "source": [
    "# prediction on the training dataset\n",
    "mae_train = mean_absolute_error(clf.predict(featureTrain),targetTrain['verified'])\n",
    "print('mae train = '+ str(mae_train))\n",
    "\n",
    "# prediction on the testing dataset\n",
    "mae_test = mean_absolute_error(clf.predict(featureTest),targetTest['verified'])\n",
    "print('mae test = '+ str(mae_test))\n",
    "\n",
    "# prediction on the testing dataset\n",
    "mse_test = mean_squared_error(clf.predict(featureTest),targetTest['verified'])\n",
    "print('mse test = '+ str(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fitting a Gradient Boost\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "clf = GradientBoostingRegressor(learning_rate=0.1, n_estimators=200)\n",
    "clf.fit(featureTrain, targetTrainIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on the training dataset\n",
    "mae_train = mean_absolute_error(clf.predict(featureTrain),targetTrain['verified'])\n",
    "print('mae train = '+ str(mae_train))\n",
    "\n",
    "# prediction on the testing dataset\n",
    "mae_test = mean_absolute_error(clf.predict(featureTest),targetTest['verified'])\n",
    "print('mae test = '+ str(mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlai_kernel",
   "language": "python",
   "name": "wlai_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
