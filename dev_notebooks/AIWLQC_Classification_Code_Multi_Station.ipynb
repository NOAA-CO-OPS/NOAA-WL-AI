{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 12/21/2023\n",
    "\n",
    "#---Jimmy's test AI WL QC model that currently does the following:---  \n",
    "#-User defines station IDs, file names, binarization threshold, and hyperparameters for the neural net\n",
    "#-Loads the train/validation/test data for multiple stations\n",
    "#-Separates the 8 training features from the target values into X or Y for all datasets\n",
    "#-Can apply random undersampling to the training data (uncomment and select a training option)\n",
    "#-Can apply class weighting to the training data (uncomment and select a training option)\n",
    "#-Builds the neural network model\n",
    "#-Trains the model using the training dataset then performs a prediction on the validation data each epoch\n",
    "#-Outputs the training/validation metrics per epoch in a csv\n",
    "#-Performs predictions with the fully trained model on the validation data and outputs predictions in a csv \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# User defined list of station IDs for file loading\n",
    "station_ids = ['1612340','1617433','8418150','8443970','8447386','8449130','8452660','8452944','8454049','8461490','8510560','8534720','8536110','8557380','8573364','8574680','8651370','8658120','8658163','8665530','8670870','8720030','8721604','8723214','8726520','8726607','8729108','8729840','8735180','8736897','8737048','8741533','8767816','8767961','8771341','8771450','8775870','8779770','9410840','9411340','9414290','9414750','9418767','9419750','9432780','9435380','9446484','9447130','9451054','9451600','9459450','9459881','9462450','9462620','9751381','9751639']\n",
    "\n",
    "# User defined output file names\n",
    "test_number = '3' #Update every time you run the code- appends a number to the output file names\n",
    "output_metrics_file = f'out/metrics/metrics_{test_number}.csv'\n",
    "output_model_file = f'out/models/model_{test_number}.h5'\n",
    "output_val_predictions_file = f'out/predictions/val_pred_{test_number}.csv'\n",
    "output_test_predictions_file = f'out/predictions/test_pred_{test_number}.csv'\n",
    "\n",
    "# User defined binarization threshold for both validation and testing\n",
    "threshold= 0.2 #0.5 was the default value\n",
    "\n",
    "# User defined undersampling ratio (adjust as needed)\n",
    "undersampling_ratio = 0.1\n",
    "\n",
    "# User defined Hyperparameters\n",
    "input_neurons = 8\n",
    "hidden_layer1_neurons = 64\n",
    "hidden_layer2_neurons = 32\n",
    "output_neurons = 1\n",
    "learning_rate = 0.001\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "# Creation of a Validation callback to provide useful metrics per epoch during training\n",
    "class ValidationMetricsCallback(Callback):\n",
    "    def __init__(self, X_val, y_val, threshold):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.threshold = threshold\n",
    "        self.validation_metrics = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calculate accuracy for predicting \"bad\" points on the validation set\n",
    "        y_pred_val = (self.model.predict(self.X_val) >= self.threshold).astype(int).flatten()\n",
    "        true_bad_points_val = self.y_val[self.y_val == 0]\n",
    "        predicted_bad_points_val = y_pred_val[self.y_val == 0]\n",
    "        accuracy_bad_points_val = accuracy_score(true_bad_points_val, predicted_bad_points_val)\n",
    "\n",
    "        # Calculate the number of instances where y_pred_val was 0 but y_true_val was 1\n",
    "        false_negatives_val = np.sum((y_pred_val == 0) & (self.y_val == 1))\n",
    "        \n",
    "        # Print and store the accuracy and false negatives for each epoch\n",
    "        print(f'Epoch {epoch + 1} - Validation Accuracy for \"Bad\" Points: {accuracy_bad_points_val * 100:.2f}%')\n",
    "        print(f'Epoch {epoch + 1} - Validation False Negatives: {false_negatives_val}')\n",
    "        \n",
    "        self.validation_metrics.append({\n",
    "            'Validation_Accuracy_Bad_Points': accuracy_bad_points_val,\n",
    "            'False_Negatives_Val': false_negatives_val\n",
    "        })\n",
    "\n",
    "# Load the data for each station and concatenate them\n",
    "all_train_data = []\n",
    "all_test_data = []\n",
    "all_val_data = []\n",
    "\n",
    "for station_id in station_ids:\n",
    "    train_file = f'data/{station_id}_processed_ver_merged_wl_train.csv'\n",
    "    test_file = f'data/{station_id}_processed_ver_merged_wl_test.csv'\n",
    "    val_file = f'data/{station_id}_processed_ver_merged_wl_validation.csv'\n",
    "\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file) and os.path.isfile(val_file):\n",
    "        train_data_station = pd.read_csv(train_file)\n",
    "        test_data_station = pd.read_csv(test_file)\n",
    "        val_data_station = pd.read_csv(val_file)\n",
    "\n",
    "        all_train_data.append(train_data_station)\n",
    "        all_test_data.append(test_data_station)\n",
    "        all_val_data.append(val_data_station)\n",
    "\n",
    "# Concatenate data for all stations\n",
    "train_data = pd.concat(all_train_data, ignore_index=True)\n",
    "test_data = pd.concat(all_test_data, ignore_index=True)\n",
    "val_data = pd.concat(all_val_data, ignore_index=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data[['PRIMARY', 'PRIMARY_TRUE', 'PRIMARY_SIGMA', 'PRIMARY_SIGMA_TRUE', 'PRIMARY_RESIDUAL', 'BACKUP', 'BACKUP_TRUE', 'PREDICTION']].values\n",
    "y_train = train_data['TARGET'].values\n",
    "\n",
    "X_test = test_data[['PRIMARY', 'PRIMARY_TRUE', 'PRIMARY_SIGMA', 'PRIMARY_SIGMA_TRUE', 'PRIMARY_RESIDUAL', 'BACKUP', 'BACKUP_TRUE', 'PREDICTION']].values\n",
    "y_test = test_data['TARGET'].values\n",
    "\n",
    "X_val = val_data[['PRIMARY', 'PRIMARY_TRUE', 'PRIMARY_SIGMA', 'PRIMARY_SIGMA_TRUE', 'PRIMARY_RESIDUAL', 'BACKUP', 'BACKUP_TRUE', 'PREDICTION']].values\n",
    "y_val = val_data['TARGET'].values\n",
    "\n",
    "\n",
    "#Options to add undersampling/class weights# ---------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Apply random undersampling \n",
    "#rus = RandomUnderSampler(sampling_strategy=undersampling_ratio, random_state=42)\n",
    "#X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of each class after resampling\n",
    "#class_counts_resampled = pd.Series(y_train_resampled).value_counts()\n",
    "#print(\"Class Counts After Resampling:\")\n",
    "#print(class_counts_resampled)\n",
    "\n",
    "\n",
    "# Calculate class weights to be used in training\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "#class_weight = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Calculate class weights to be used in training along with undersampling\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "#class_weight = dict(zip(np.unique(y_train_resampled), class_weights))\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(hidden_layer1_neurons, activation='relu', input_shape=(input_neurons,)),\n",
    "    Dense(hidden_layer2_neurons, activation='relu'),\n",
    "    Dense(output_neurons, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define and compile the model before creating the callback\n",
    "validation_metrics_callback = ValidationMetricsCallback(X_val, y_val, threshold)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#TRAINING OPTIONS- Choose One\n",
    "\n",
    "#Train the model \n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[validation_metrics_callback])\n",
    "\n",
    "# Train the model with class weights\n",
    "#history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[validation_metrics_callback], class_weight=class_weight )\n",
    "\n",
    "# Train the model with the resampled data\n",
    "#history = model.fit(X_train_resampled, y_train_resampled, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[validation_metrics_callback])\n",
    "\n",
    "# Train the model with the resampled data and class weights\n",
    "#history = model.fit(X_train_resampled, y_train_resampled, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[validation_metrics_callback], class_weight=class_weight)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Save the trained model\n",
    "model.save(output_model_file)\n",
    "\n",
    "# Extract training metrics\n",
    "training_metrics = pd.DataFrame({\n",
    "    'Epoch': range(1, len(history.history['accuracy']) + 1),\n",
    "    'Training_Loss': history.history['loss'],\n",
    "    'Training_Accuracy': history.history['accuracy'],\n",
    "    'Validation_Loss': history.history['val_loss'],\n",
    "    'Validation_Accuracy': history.history['val_accuracy']\n",
    "})\n",
    "\n",
    "# Include the validation metrics for \"bad\" points in the training metrics DataFrame\n",
    "validation_metrics_df = pd.DataFrame(validation_metrics_callback.validation_metrics)\n",
    "training_metrics = pd.concat([training_metrics, validation_metrics_df], axis=1)\n",
    "\n",
    "# Save training metrics to CSV\n",
    "training_metrics.to_csv(output_metrics_file, index=False)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Code to predict and output predictions csv for validation data below:\n",
    "\n",
    "# Create Function to output validation predictions in a csv\n",
    "def output_predictions_csv_validation(X_val, y_val, primary_values, station_ids, file_path, accuracy_val_set, accuracy_bad_points_val_set, false_negatives_val_set, threshold):\n",
    "    y_pred_probs_val = model.predict(X_val)\n",
    "    y_pred_binary_val = (y_pred_probs_val >= threshold).astype(int).flatten()  # Apply the threshold\n",
    "\n",
    "    df_val = pd.DataFrame({\n",
    "        'DATE_TIME': val_data['DATE_TIME'],  # Assuming 'val_data' is your validation data\n",
    "        'PRIMARY': primary_values,\n",
    "        'STATION_ID': station_ids,\n",
    "        'True_Target': y_val,\n",
    "        'Predicted_Target': y_pred_binary_val,\n",
    "        'Prediction_Score': y_pred_probs_val.flatten(),\n",
    "    })\n",
    "\n",
    "    # Add accuracy-related columns with a header row and one value row\n",
    "    df_val = pd.concat([\n",
    "        df_val,\n",
    "        pd.DataFrame({\n",
    "            'Accuracy_Val_Set': [accuracy_val_set],\n",
    "            'Accuracy_Bad_Points_Val_Set': [accuracy_bad_points_val_set],\n",
    "            'False_Negatives_Val_Set': [false_negatives_val_set]\n",
    "        })\n",
    "    ], axis=1)\n",
    "\n",
    "# Calculate accuracy on bad points and false negatives for each unique STATION_ID\n",
    "    station_accuracy_bad_points_val = []\n",
    "    station_false_negatives_val = []\n",
    "\n",
    "    unique_stations_val = df_val['STATION_ID'].unique()\n",
    "    for station_id_val in unique_stations_val:\n",
    "        station_df_val = df_val[df_val['STATION_ID'] == station_id_val]\n",
    "        true_bad_points_station_val = station_df_val['True_Target'][station_df_val['True_Target'] == 0]\n",
    "        predicted_bad_points_station_val = station_df_val['Predicted_Target'][station_df_val['True_Target'] == 0]\n",
    "        accuracy_bad_points_station_val = accuracy_score(true_bad_points_station_val, predicted_bad_points_station_val) * 100\n",
    "        false_negatives_station_val = np.sum((station_df_val['Predicted_Target'] == 0) & (station_df_val['True_Target'] == 1))\n",
    "\n",
    "        station_accuracy_bad_points_val.append(accuracy_bad_points_station_val)\n",
    "        station_false_negatives_val.append(false_negatives_station_val)\n",
    "\n",
    "    # Add new columns to the DataFrame\n",
    "    df_val = pd.concat([\n",
    "        df_val,\n",
    "        pd.DataFrame({\n",
    "            'Station_ID_Results_Val': unique_stations_val,\n",
    "            'Accuracy_Bad_Points_Station_Val': station_accuracy_bad_points_val,\n",
    "            'False_Negatives_Station_Val': station_false_negatives_val\n",
    "        })\n",
    "    ], axis=1)\n",
    "\n",
    "    # Reorder the columns\n",
    "    df_val = df_val[['DATE_TIME', 'STATION_ID', 'PRIMARY', 'True_Target', 'Predicted_Target', 'Prediction_Score', 'Accuracy_Val_Set',\n",
    "                     'Accuracy_Bad_Points_Val_Set', 'False_Negatives_Val_Set', 'Station_ID_Results_Val',\n",
    "                     'Accuracy_Bad_Points_Station_Val', 'False_Negatives_Station_Val']]\n",
    "\n",
    "    df_val.to_csv(file_path, index=False)\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_binary_val = (y_pred_val >= threshold).astype(int).flatten()  # Apply the threshold\n",
    "\n",
    "#Calculates a prediction total accuracy on the validation data\n",
    "accuracy_val = accuracy_score(y_val, y_pred_binary_val)\n",
    "print(f'Accuracy on validation set: {accuracy_val * 100:.2f}%')\n",
    "\n",
    "#Defines true bad points and predicted bad points in validation data\n",
    "true_bad_points_val = y_val[y_val == 0]\n",
    "predicted_bad_points_val = y_pred_binary_val[y_val == 0]\n",
    "\n",
    "#calculates a prediciton accuracy score for just bad points in validation data\n",
    "accuracy_bad_points_val = accuracy_score(true_bad_points_val, predicted_bad_points_val) * 100\n",
    "print(f'Accuracy for predicting \"bad\" points on validation set: {accuracy_bad_points_val:.2f}%')\n",
    "\n",
    "# Calculate the number of false negatives for the validation set\n",
    "false_negatives_val_set = np.sum((y_pred_binary_val == 0) & (y_val == 1))\n",
    "print(f'Number of False Negatives on validation set: {false_negatives_val_set}')\n",
    "\n",
    "# Create variables to store evaluation metrics for validation set\n",
    "accuracy_val_set = accuracy_val * 100\n",
    "accuracy_bad_points_val_set = accuracy_bad_points_val\n",
    "\n",
    "# Use the function to output predictions for validation data\n",
    "output_predictions_csv_validation(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    val_data['PRIMARY'].values,\n",
    "    val_data['STATION_ID'].values,\n",
    "    output_val_predictions_file,\n",
    "    accuracy_val_set,\n",
    "    accuracy_bad_points_val_set,\n",
    "    false_negatives_val_set,\n",
    "    threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL CELL TO PREDICT AND CREATE OUTPUT PREDICTIONS CSV FOR TEST DATA\n",
    "\n",
    "# Function for test output predicitons CSV\n",
    "def output_predictions_csv(X, y_true, primary_values, station_ids, file_path, accuracy_test_set, accuracy_bad_points_test_set, false_negatives_test_set, threshold):\n",
    "    y_pred_probs = model.predict(X)\n",
    "    y_pred_binary = (y_pred_probs >= threshold).astype(int).flatten()  # Apply the threshold\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'DATE_TIME': test_data['DATE_TIME'],\n",
    "        'STATION_ID': station_ids,\n",
    "        'PRIMARY': primary_values,\n",
    "        'True_Target': y_true,\n",
    "        'Predicted_Target': y_pred_binary,\n",
    "        'Prediction_Score': y_pred_probs.flatten(),\n",
    "    })\n",
    "\n",
    "    # Add accuracy-related columns with a header row and one value row\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame({\n",
    "            'Accuracy_Test_Set': [accuracy_test_set],\n",
    "            'Accuracy_Bad_Points_Test_Set': [accuracy_bad_points_test_set],\n",
    "            'False_Negatives_Test_Set': [false_negatives_test_set]\n",
    "        })\n",
    "    ], axis=1)\n",
    "\n",
    "    # Calculate accuracy on bad points and false negatives for each unique STATION_ID\n",
    "    station_accuracy_bad_points = []\n",
    "    station_false_negatives = []\n",
    "\n",
    "    unique_stations = df['STATION_ID'].unique()\n",
    "    for station_id in unique_stations:\n",
    "        station_df = df[df['STATION_ID'] == station_id]\n",
    "        true_bad_points_station = station_df['True_Target'][station_df['True_Target'] == 0]\n",
    "        predicted_bad_points_station = station_df['Predicted_Target'][station_df['True_Target'] == 0]\n",
    "        accuracy_bad_points_station = accuracy_score(true_bad_points_station, predicted_bad_points_station) *100\n",
    "        false_negatives_station = np.sum((station_df['Predicted_Target'] == 0) & (station_df['True_Target'] == 1))\n",
    "\n",
    "        station_accuracy_bad_points.append(accuracy_bad_points_station)\n",
    "        station_false_negatives.append(false_negatives_station)\n",
    "\n",
    "    # Add new columns to the DataFrame\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame({\n",
    "            'Station_ID_Results': unique_stations,\n",
    "            'Accuracy_Bad_Points_Station': station_accuracy_bad_points,\n",
    "            'False_Negatives_Station': station_false_negatives\n",
    "        })\n",
    "    ], axis=1)\n",
    "\n",
    "    # Reorder the columns\n",
    "    df = df[['DATE_TIME', 'STATION_ID', 'PRIMARY', 'True_Target', 'Predicted_Target', 'Prediction_Score', 'Accuracy_Test_Set',\n",
    "             'Accuracy_Bad_Points_Test_Set', 'False_Negatives_Test_Set', 'Station_ID_Results', 'Accuracy_Bad_Points_Station', 'False_Negatives_Station']]\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred >= threshold).astype(int).flatten()\n",
    "\n",
    "#Calculates a prediciton total accuracy score on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n",
    "\n",
    "#Defines true bad points and predicted bad points in test data\n",
    "true_bad_points = y_test[y_test == 0]\n",
    "predicted_bad_points = y_pred_binary[y_test == 0]\n",
    "\n",
    "#Calculates a prediction accuracy score for just bad points in test data\n",
    "accuracy_bad_points = accuracy_score(true_bad_points, predicted_bad_points)\n",
    "print(f'Accuracy for predicting \"bad\" points: {accuracy_bad_points * 100:.2f}%')\n",
    "\n",
    "# Calculate the number of false negatives for the test set\n",
    "false_negatives_test_set = np.sum((y_pred_binary == 0) & (y_test == 1))\n",
    "print(f'Number of False Negatives on test set: {false_negatives_test_set}')\n",
    "\n",
    "# Create variables to store evaluation metrics\n",
    "accuracy_test_set = accuracy * 100\n",
    "accuracy_bad_points_test_set = accuracy_bad_points * 100\n",
    "\n",
    "# Use the function to output predictions for test data\n",
    "output_predictions_csv(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_data['PRIMARY'].values,\n",
    "    test_data['STATION_ID'].values,\n",
    "    output_test_predictions_file,\n",
    "    accuracy_test_set,\n",
    "    accuracy_bad_points_test_set,\n",
    "    false_negatives_test_set,\n",
    "    threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlai",
   "language": "python",
   "name": "wlai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
